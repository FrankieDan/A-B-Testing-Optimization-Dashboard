# ðŸ§ª A/B Testing Optimization Dashboard â€“ Feature Performance Analysis

This project showcases an end-to-end A/B test analysis workflow using **MySQL**, **Python**, and **Tableau**, designed to assess the impact of a feature rollout on user engagement and conversion.

---

## ðŸ“Œ Project Objective

To measure and visualize the performance of a newly released feature by comparing two user cohorts (A & B) through a statistically sound A/B test. The dashboard enables product and UX teams to:

- Analyze average session time and conversion rates by cohort
- Validate statistical differences between groups
- Identify data-driven recommendations for feature release

---

## ðŸ›  Tech Stack

- **SQL (MySQL)** â€“ Data modeling, cohort aggregation, view creation  
- **Python (optional, for CSV generation)**  
- **Tableau** â€“ Interactive dashboard for feature performance visualization

---

## ðŸ“Š Dashboard Overview

The dashboard consists of:

- **Average Session Time by Cohort** â€“ Bar chart comparing user engagement
- **Conversion Rate by Cohort** â€“ Bar chart showing uplift in conversion
- **KPI Summary Table** â€“ Cohort-level metrics: users, average time, conversion %, and test duration

![image](https://github.com/user-attachments/assets/b208bffb-2091-498b-85d4-b14ba2a4548c)


---

## ðŸ“‚ Project Structure 
